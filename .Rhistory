break
}
}
plot(truegraph_, main="True graph")
data = generateGaussianDataFromGraph(adjacencyMatrix = trueGraph, n.obs=1000, n.variables=6)
X = data[[2]]
b = 1
D = 10*diag(1,dim(X)[2])
#D = solve(data[[3]])
#initialCandidate = matrix(0,nrow=6, ncol=6)
#while(TRUE){
#  init_graph = erdos.renyi.game(6,0.3,type="gnp",directed = FALSE)
#  init_cand = as_adjacency_matrix(init_graph, sparse = 0)
#  if(isDecomposable(init_cand)){
#    break
#  }
#}
#plot(init_graph, main="candidate")
#print(logMarginalLikelihoodGaussian(init_cand, X, b, D))
print(logMarginalLikelihoodGaussian(trueGraph, X, b, D))
print(logMarginalLikelihoodGaussian(initialCandidate, X, b, D))
chain = MetropolisHastingsGaussian(X, initialCandidate=initialCandidate, 50, 10, p=0.3, prior="Binomial")
}
rm(list = ls())
setwd("~/GitHub/GraphicalModels-BayesStat")
source("categorical.R")
# Generate 20 decomposable graph that will be used as the true graph to generate
# 20 different datasets
trueGraphs = list()
encodedList = c()
for(i in 1:20){
while(TRUE){
graph = erdos.renyi.game(6,0.3,type="gnp",directed = FALSE)
newGraph = as_adjacency_matrix(graph, sparse = 0)
encoded = encodeGraph(newGraph)
if(isDecomposable(newGraph) & !encoded %in% encodedList){
trueGraphs[[i]] = newGraph
encodedList = c(encodedList,encoded)
break
}
}
}
mpgs = list()
maps = list()
mpg_distances = c()
map_distances = c()
count = 1
for(trueGraph in trueGraphs){
data = generateCategoricalDataFromGraph(adjacencyMatrix = trueGraph, n.obs = 10000, n.variables = 6, p = 0.3)
initialCandidate = matrix(0,6,6)
chain = MetropolisHastingsCategorical(data[[2]],initialCandidate,1000,500,1,prior = "Binomial",p=0.3)
# Median Probability Graph
mpg = medianProbabilityGraph(chain)
mpgs[[count]] = mpg
mpg_distances = c(mpg_distances,computeSHD(trueGraph,mpg))
# Maximum a Posteriori Graph
map = maximumPosterioriGraph(chain)
maps[[count]] = map
map_distances = c(map_distances,computeSHD(trueGraph,map))
# Increase count
count = count + 1
}
x11()
par(mfrow = c(2,1))
barplot(table(mpg_distances),main = "SHD (Median Probability Graphs)", col = rainbow(length(unique(mpg_distances))))
barplot(table(map_distances),main = "SHD (Maximum a Posteriori)", col = rainbow(length(unique(map_distances))))
print(mean(mpg_distances))
print(mean(map_distances))
rm(list = ls())
setwd("~/GitHub/GraphicalModels-BayesStat")
source("Gaussian.R")
# Generate 20 decomposable graph that will be used as the true graph to generate
# 20 different datasets
number_of_trial = 20
number_of_node = 6
trueGraphs = list()
encodedList = c()
for(i in 1:number_of_trial){
while(TRUE){
graph = erdos.renyi.game(number_of_node,0.3,type="gnp",directed = FALSE)
newGraph = as_adjacency_matrix(graph, sparse = 0)
encoded = encodeGraph(newGraph)
if(isDecomposable(newGraph) & !encoded %in% encodedList){
trueGraphs[[i]] = newGraph
encodedList = c(encodedList,encoded)
break
}
}
}
mpgs = list()
maps = list()
mpg_distances = c()
map_distances = c()
count = 1
for(trueGraph in trueGraphs){
data = generateGaussianDataFromGraph(adjacencyMatrix = trueGraph, n.obs = 10000, n.variables = number_of_node)
initialCandidate = matrix(0,number_of_node,number_of_node)
print(paste("graph ", count))
chain = MetropolisHastingsGaussian(data[[2]], initialCandidate, 200, 50, 1, prior = "Binomial", p=0.3)
# Median Probability Graph
mpg = medianProbabilityGraph(chain)
mpgs[[count]] = mpg
mpg_distances = c(mpg_distances,computeSHD(trueGraph,mpg))
# Maximum a Posteriori Graph
map = maximumPosterioriGraph(chain)
maps[[count]] = map
map_distances = c(map_distances,computeSHD(trueGraph,map))
# Increase count
count = count + 1
}
x11()
par(mfrow = c(2,1))
barplot(table(mpg_distances),main = "SHD (Median Probability Graphs)", col = rainbow(length(unique(mpg_distances))))
barplot(table(map_distances),main = "SHD (Maximum a Posteriori)", col = rainbow(length(unique(map_distances))))
print(mean(mpg_distances))
print(mean(map_distances))
source("Gaussian.R")
rm(list = ls())
setwd("~/GitHub/GraphicalModels-BayesStat")
source("Gaussian.R")
rm(list = ls())
setwd("~/GitHub/GraphicalModels-BayesStat")
source("Gaussian.R")
# Generate 20 decomposable graph that will be used as the true graph to generate
# 20 different datasets
number_of_trial = 1
number_of_node = 6
trueGraphs = list()
encodedList = c()
for(i in 1:number_of_trial){
while(TRUE){
graph = erdos.renyi.game(number_of_node,0.3,type="gnp",directed = FALSE)
newGraph = as_adjacency_matrix(graph, sparse = 0)
encoded = encodeGraph(newGraph)
if(isDecomposable(newGraph) & !encoded %in% encodedList){
trueGraphs[[i]] = newGraph
encodedList = c(encodedList,encoded)
break
}
}
}
mpgs = list()
maps = list()
mpg_distances = c()
map_distances = c()
count = 1
for(trueGraph in trueGraphs){
data = generateCategoricalDataFromGraph(adjacencyMatrix = trueGraph, n.obs = 1000, n.variables = number_of_node, p = 0.3)
initialCandidate = matrix(0,number_of_node,number_of_node)
print(paste("graph ", count))
chain = MetropolisHastingsGaussianCategorical(data[[2]], initialCandidate, 200, 50, 1, prior = "Binomial", p=0.3)
# Median Probability Graph
mpg = medianProbabilityGraph(chain)
mpgs[[count]] = mpg
mpg_distances = c(mpg_distances,computeSHD(trueGraph,mpg))
# Maximum a Posteriori Graph
map = maximumPosterioriGraph(chain)
maps[[count]] = map
map_distances = c(map_distances,computeSHD(trueGraph,map))
# Increase count
count = count + 1
}
x11()
par(mfrow = c(2,1))
barplot(table(mpg_distances),main = "SHD (Median Probability Graphs)", col = rainbow(length(unique(mpg_distances))))
barplot(table(map_distances),main = "SHD (Maximum a Posteriori)", col = rainbow(length(unique(map_distances))))
print(mean(mpg_distances))
print(mean(map_distances))
View(data)
MetropolisHastingsGaussianCategorical = function(data, initialCandidate, n.iter, burnin = 0, thin = 1, prior, p = NULL, b = NULL){
# We check that the passed parameters are correct
if(!prior %in% c("Uniform","Binomial","Beta-Binomial")){
stop("prior should be either 'Uniform', 'Binomial' or 'Beta-Binomial'!")
}
if(!isDecomposable(initialCandidate)){
stop("Initial candidate graph should be decomposable!")
}
currentCandidate = initialCandidate
b = 1 #degress of freedom of the Hyperinverse Whishart
n = dim(data)[1]
D = 10 * diag(1, dim(data)[2]) #parameter D of the Hyperinverse Whishart
x = data.matrix(data)
tau_prior = 1 #std deviation prior on the cutoffs vector
#initialization
tetha = rep(0, dim(x)[2]) #initialize tetha with zeros
lower_bounds_matrix = lower_bounds(tetha, x)
upper_bounds_matrix = upper_bounds(tetha, x)
Z = generate_Z(n=n, sigma=D, lower=lower_bounds_matrix, upper=upper_bounds_matrix, algorithm="gibbs")
Sigma = D + t(Z)%*%Z
D_star = Sigma
# Run the burnin iterations
if(burnin!=0){
message("BURN-IN")
progressBarBI = txtProgressBar(min = 0, max = burnin, initial = 0, style = 3)
for(i in 1:burnin){
setTxtProgressBar(progressBarBI,i)
theta = MH_tetha(Sigma=Sigma, x=x, tau_prior=tau_prior, tetha=tetha) #updata tetha vector with a MH step
Sigma = update_Sigma(df=b+n, Dstar=D_star, adj=adj) #update Sigma
Z = generate_Z(sigma=Sigma, lower=lower_bounds_matrix, upper=upper_bounds_matrix, algorithm="gibbs")
D_star = D + t(Z)%*%Z #update D_star for the HWS
newCandidate = newGraphProposal(currentCandidate)
num = logMarginalLikelihoodGaussian(newCandidate,data, b, D, D_star=D_star)
den = logMarginalLikelihoodGaussian(currentCandidate,data, b, D, D_star=D_star)
marginalRatio = exp(num - den)
priorRatio = switch(prior, "Uniform" = 1, "Binomial" = binomialPrior(currentCandidate,newCandidate,p), "Beta-Binomial" = betaBinomialPrior(currentCandidate,newCandidate,a,b))
acceptanceProbability = min(marginalRatio * priorRatio,1)
accepted = rbern(1,acceptanceProbability)
if(accepted == 1){
currentCandidate = newCandidate
}
}
close(progressBarBI)
}
# Run the chain
message("Metropolis-Hastings")
progressBar = txtProgressBar(min = 0, max = n.iter, initial = 0, style = 3)
chain = list()
c = 0
for(i in 1:n.iter){
setTxtProgressBar(progressBar,i)
theta = MH_tetha(Sigma=Sigma, x=x, tau_prior=tau_prior, tetha=tetha) #updata tetha vector with a MH step
Sigma = update_Sigma(df=b+n, Dstar=D_star, adj=adj) #update Sigma
Z = generate_Z(sigma=Sigma, lower=lower_bounds_matrix, upper=upper_bounds_matrix, algorithm="gibbs")
D_star = D + t(Z)%*%Z #update D_star for the HWS
newCandidate = newGraphProposal(currentCandidate)
num = logMarginalLikelihoodGaussian(newCandidate,data,b, D)
den = logMarginalLikelihoodGaussian(currentCandidate,data,b, D)
marginalRatio = exp(num - den)
priorRatio = switch(prior, "Uniform" = 1, "Binomial" = binomialPrior(currentCandidate,newCandidate,p), "Beta-Binomial" = betaBinomialPrior(currentCandidate,newCandidate,a,b))
acceptanceProbability = min(marginalRatio * priorRatio,1)
accepted = rbern(1,acceptanceProbability)
c = c + accepted
if(accepted == 1){
currentCandidate = newCandidate
}
if(i %% thin == 0){
chain[[i/thin]] = currentCandidate
}
}
if(burnin!=0){
close(progressBarBI)
}
cat(paste0("\nThe average acceptance rate is: ", as.character(c / n.iter),"\n"))
return(chain)
}
update_Sigma = function(df, Dstar, adj){
inv.covariance = rgwish(n = 1, adj = adj, b = df, D = Dstar)
covariance = solve(inv.covariance)
return(covariance)
}
rm(list = ls())
setwd("~/GitHub/GraphicalModels-BayesStat")
source("Gaussian.R")
# Generate 20 decomposable graph that will be used as the true graph to generate
# 20 different datasets
number_of_trial = 1
number_of_node = 6
trueGraphs = list()
encodedList = c()
for(i in 1:number_of_trial){
while(TRUE){
graph = erdos.renyi.game(number_of_node,0.3,type="gnp",directed = FALSE)
newGraph = as_adjacency_matrix(graph, sparse = 0)
encoded = encodeGraph(newGraph)
if(isDecomposable(newGraph) & !encoded %in% encodedList){
trueGraphs[[i]] = newGraph
encodedList = c(encodedList,encoded)
break
}
}
}
mpgs = list()
maps = list()
mpg_distances = c()
map_distances = c()
count = 1
for(trueGraph in trueGraphs){
data = generateCategoricalDataFromGraph(adjacencyMatrix = trueGraph, n.obs = 1000, n.variables = number_of_node, p = 0.3)
initialCandidate = matrix(0,number_of_node,number_of_node)
print(paste("graph ", count))
chain = MetropolisHastingsGaussianCategorical(data[[2]], initialCandidate, 200, 50, 1, prior = "Binomial", p=0.3)
# Median Probability Graph
mpg = medianProbabilityGraph(chain)
mpgs[[count]] = mpg
mpg_distances = c(mpg_distances,computeSHD(trueGraph,mpg))
# Maximum a Posteriori Graph
map = maximumPosterioriGraph(chain)
maps[[count]] = map
map_distances = c(map_distances,computeSHD(trueGraph,map))
# Increase count
count = count + 1
}
rm(list = ls())
setwd("~/GitHub/GraphicalModels-BayesStat")
source("Gaussian.R")
# Generate 20 decomposable graph that will be used as the true graph to generate
# 20 different datasets
number_of_trial = 1
number_of_node = 6
trueGraphs = list()
encodedList = c()
for(i in 1:number_of_trial){
while(TRUE){
graph = erdos.renyi.game(number_of_node,0.3,type="gnp",directed = FALSE)
newGraph = as_adjacency_matrix(graph, sparse = 0)
encoded = encodeGraph(newGraph)
if(isDecomposable(newGraph) & !encoded %in% encodedList){
trueGraphs[[i]] = newGraph
encodedList = c(encodedList,encoded)
break
}
}
}
mpgs = list()
maps = list()
mpg_distances = c()
map_distances = c()
count = 1
for(trueGraph in trueGraphs){
data = generateCategoricalDataFromGraph(adjacencyMatrix = trueGraph, n.obs = 1000, n.variables = number_of_node, p = 0.3)
initialCandidate = matrix(0,number_of_node,number_of_node)
print(paste("graph ", count))
chain = MetropolisHastingsGaussianCategorical(data[[2]], initialCandidate, 200, 50, 1, prior = "Binomial", p=0.3)
# Median Probability Graph
mpg = medianProbabilityGraph(chain)
mpgs[[count]] = mpg
mpg_distances = c(mpg_distances,computeSHD(trueGraph,mpg))
# Maximum a Posteriori Graph
map = maximumPosterioriGraph(chain)
maps[[count]] = map
map_distances = c(map_distances,computeSHD(trueGraph,map))
# Increase count
count = count + 1
}
rm(list = ls())
setwd("~/GitHub/GraphicalModels-BayesStat")
source("Gaussian.R")
# Generate 20 decomposable graph that will be used as the true graph to generate
# 20 different datasets
number_of_trial = 1
number_of_node = 6
trueGraphs = list()
encodedList = c()
for(i in 1:number_of_trial){
while(TRUE){
graph = erdos.renyi.game(number_of_node,0.3,type="gnp",directed = FALSE)
newGraph = as_adjacency_matrix(graph, sparse = 0)
encoded = encodeGraph(newGraph)
if(isDecomposable(newGraph) & !encoded %in% encodedList){
trueGraphs[[i]] = newGraph
encodedList = c(encodedList,encoded)
break
}
}
}
mpgs = list()
maps = list()
mpg_distances = c()
map_distances = c()
count = 1
for(trueGraph in trueGraphs){
data = generateCategoricalDataFromGraph(adjacencyMatrix = trueGraph, n.obs = 1000, n.variables = number_of_node, p = 0.3)
initialCandidate = matrix(0,number_of_node,number_of_node)
print(paste("graph ", count))
chain = MetropolisHastingsGaussianCategorical(data[[2]], initialCandidate, 200, 50, 1, prior = "Binomial", p=0.3)
# Median Probability Graph
mpg = medianProbabilityGraph(chain)
mpgs[[count]] = mpg
mpg_distances = c(mpg_distances,computeSHD(trueGraph,mpg))
# Maximum a Posteriori Graph
map = maximumPosterioriGraph(chain)
maps[[count]] = map
map_distances = c(map_distances,computeSHD(trueGraph,map))
# Increase count
count = count + 1
}
rm(list = ls())
setwd("~/GitHub/GraphicalModels-BayesStat")
source("Gaussian.R")
# Generate 20 decomposable graph that will be used as the true graph to generate
# 20 different datasets
number_of_trial = 1
number_of_node = 6
trueGraphs = list()
encodedList = c()
for(i in 1:number_of_trial){
while(TRUE){
graph = erdos.renyi.game(number_of_node,0.3,type="gnp",directed = FALSE)
newGraph = as_adjacency_matrix(graph, sparse = 0)
encoded = encodeGraph(newGraph)
if(isDecomposable(newGraph) & !encoded %in% encodedList){
trueGraphs[[i]] = newGraph
encodedList = c(encodedList,encoded)
break
}
}
}
mpgs = list()
maps = list()
mpg_distances = c()
map_distances = c()
count = 1
for(trueGraph in trueGraphs){
data = generateCategoricalDataFromGraph(adjacencyMatrix = trueGraph, n.obs = 1000, n.variables = number_of_node, p = 0.3)
initialCandidate = matrix(0,number_of_node,number_of_node)
print(paste("graph ", count))
chain = MetropolisHastingsGaussianCategorical(data[[2]], initialCandidate, 200, 50, 1, prior = "Binomial", p=0.3)
# Median Probability Graph
mpg = medianProbabilityGraph(chain)
mpgs[[count]] = mpg
mpg_distances = c(mpg_distances,computeSHD(trueGraph,mpg))
# Maximum a Posteriori Graph
map = maximumPosterioriGraph(chain)
maps[[count]] = map
map_distances = c(map_distances,computeSHD(trueGraph,map))
# Increase count
count = count + 1
}
rm(list = ls())
setwd("~/GitHub/GraphicalModels-BayesStat")
source("Gaussian.R")
# Generate 20 decomposable graph that will be used as the true graph to generate
# 20 different datasets
number_of_trial = 1
number_of_node = 6
trueGraphs = list()
encodedList = c()
for(i in 1:number_of_trial){
while(TRUE){
graph = erdos.renyi.game(number_of_node,0.3,type="gnp",directed = FALSE)
newGraph = as_adjacency_matrix(graph, sparse = 0)
encoded = encodeGraph(newGraph)
if(isDecomposable(newGraph) & !encoded %in% encodedList){
trueGraphs[[i]] = newGraph
encodedList = c(encodedList,encoded)
break
}
}
}
mpgs = list()
maps = list()
mpg_distances = c()
map_distances = c()
count = 1
for(trueGraph in trueGraphs){
data = generateCategoricalDataFromGraph(adjacencyMatrix = trueGraph, n.obs = 1000, n.variables = number_of_node, p = 0.3)
initialCandidate = matrix(0,number_of_node,number_of_node)
print(paste("graph ", count))
chain = MetropolisHastingsGaussianCategorical(data[[2]], initialCandidate, 200, 50, 1, prior = "Binomial", p=0.3)
# Median Probability Graph
mpg = medianProbabilityGraph(chain)
mpgs[[count]] = mpg
mpg_distances = c(mpg_distances,computeSHD(trueGraph,mpg))
# Maximum a Posteriori Graph
map = maximumPosterioriGraph(chain)
maps[[count]] = map
map_distances = c(map_distances,computeSHD(trueGraph,map))
# Increase count
count = count + 1
}
rm(list = ls())
setwd("~/GitHub/GraphicalModels-BayesStat")
source("Gaussian.R")
# Generate 20 decomposable graph that will be used as the true graph to generate
# 20 different datasets
number_of_trial = 1
number_of_node = 6
trueGraphs = list()
encodedList = c()
for(i in 1:number_of_trial){
while(TRUE){
graph = erdos.renyi.game(number_of_node,0.3,type="gnp",directed = FALSE)
newGraph = as_adjacency_matrix(graph, sparse = 0)
encoded = encodeGraph(newGraph)
if(isDecomposable(newGraph) & !encoded %in% encodedList){
trueGraphs[[i]] = newGraph
encodedList = c(encodedList,encoded)
break
}
}
}
mpgs = list()
maps = list()
mpg_distances = c()
map_distances = c()
count = 1
for(trueGraph in trueGraphs){
data = generateCategoricalDataFromGraph(adjacencyMatrix = trueGraph, n.obs = 100, n.variables = number_of_node, p = 0.3)
initialCandidate = matrix(0,number_of_node,number_of_node)
print(paste("graph ", count))
chain = MetropolisHastingsGaussianCategorical(data[[2]], initialCandidate, 100, 50, 1, prior = "Binomial", p=0.3)
# Median Probability Graph
mpg = medianProbabilityGraph(chain)
mpgs[[count]] = mpg
mpg_distances = c(mpg_distances,computeSHD(trueGraph,mpg))
# Maximum a Posteriori Graph
map = maximumPosterioriGraph(chain)
maps[[count]] = map
map_distances = c(map_distances,computeSHD(trueGraph,map))
# Increase count
count = count + 1
}
x11()
par(mfrow = c(2,1))
barplot(table(mpg_distances),main = "SHD (Median Probability Graphs)", col = rainbow(length(unique(mpg_distances))))
barplot(table(map_distances),main = "SHD (Maximum a Posteriori)", col = rainbow(length(unique(map_distances))))
print(mean(mpg_distances))
print(mean(map_distances))
map
mpg
trueGraph
print(mpg)
